{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Databricks notebook source\n# MAGIC %md\n# MAGIC # Football Data ETL Process\n# MAGIC This notebook performs an ETL process on football data using PySpark in Databricks.\n\n# COMMAND ----------\n\n# MAGIC\n",
                "import logging\nimport fs\nfrom pyspark.sql import functions as F\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import broadcast\n\n# COMMAND ----------\n\n# MAGIC %md\n# MAGIC ## Configure Logging\n# MAGIC Set up logging to capture information about the ETL process.\n\n# COMMAND ----------\n\n# MAGIC\n",
                "logging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# COMMAND ----------\n\n# MAGIC %md\n# MAGIC ## Step 1: Data Source Configuration\n# MAGIC Load data from Unity Catalog tables.\n\n# COMMAND ----------\n\n# MAGIC\n",
                "try:\n    logger.info(\"Loading data from Unity Catalog tables.\")\n\n    # Step 2: Data Ingestion\n    df_football = spark.table(\"catalog.db.football_data\")\n    df_other = spark.table(\"catalog.db.other_data\").select(\"team_id\", \"other_column\")  # Select only necessary columns\n\n    logger.info(\"Data ingestion completed successfully.\")\n\n# COMMAND ----------\n\n# MAGIC %md\n# MAGIC ## Step 3: Data Cleaning\n# MAGIC Remove duplicates and fill missing values.\n\n# COMMAND ----------\n\n# MAGIC\n",
                "logger.info(\"Starting data cleaning process.\")\n    df_cleaned = df_football.dropDuplicates().na.fill({'goals': 0})\n    logger.info(\"Data cleaning completed successfully.\")\n\n# COMMAND ----------\n\n# MAGIC %md\n# MAGIC ## Step 4: Data Transformation\n# MAGIC Calculate goal difference.\n\n# COMMAND ----------\n\n# MAGIC\n",
                "logger.info(\"Starting data transformation process.\")\n    df_transformed = df_cleaned.withColumn('goal_difference', F.col('goals_for') - F.col('goals_against'))\n    logger.info(\"Data transformation completed successfully.\")\n\n# COMMAND ----------\n\n# MAGIC %md\n# MAGIC ## Step 5: Data Integration\n# MAGIC Join the transformed data with other data using a broadcast join.\n\n# COMMAND ----------\n\n# MAGIC\n",
                "logger.info(\"Starting data integration process.\")\n    df_combined = df_transformed.join(broadcast(df_other), \"team_id\", 'inner')  # Use broadcast join if df_other is small\n    logger.info(\"Data integration completed successfully.\")\n\n# COMMAND ----------\n\n# MAGIC %md\n# MAGIC ## Step 6: Output Generation\n# MAGIC Write the final dataset to Unity Catalog.\n\n# COMMAND ----------\n\n# MAGIC\n",
                "logger.info(\"Writing the final dataset to Unity Catalog.\")\n    df_combined.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"catalog.db.football_performance_analysis\")\n    logger.info(\"Output generation completed successfully.\")\n\nexcept Exception as e:\n    logger.error(\"An error occurred during the ETL process: %s\", e)\n    raise\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.x"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}